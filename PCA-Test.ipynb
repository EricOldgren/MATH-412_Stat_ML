{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "import torch, torch_pca, gc\n",
    "from torchvision import datasets, transforms\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "SIDE_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imports\n",
    "train_transforms=transforms.Compose([\n",
    "        transforms.Resize((SIDE_LENGTH, SIDE_LENGTH)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        #transforms.Grayscale(),\n",
    "        transforms.ToTensor(),])\n",
    "\n",
    "test_transforms=transforms.Compose([\n",
    "        transforms.Resize((SIDE_LENGTH, SIDE_LENGTH)),\n",
    "        #transforms.Grayscale(),\n",
    "        transforms.ToTensor(),])\n",
    "\n",
    "train_dataset = datasets.Imagenette(transform=train_transforms, size=\"320px\", root='data', split='train')\n",
    "test_dataset = datasets.Imagenette(transform=test_transforms, size=\"320px\", root='data', split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_pca(channel_index: int, n_components: int, dtype=torch.float16):\n",
    "    \"\"\"Computes the pca over one channel over the training set.\"\"\"\n",
    "    global train_dataset, SIDE_LENGTH\n",
    "    data = torch.empty(len(train_dataset), SIDE_LENGTH, SIDE_LENGTH, dtype=dtype)\n",
    "    for (i, d) in enumerate(train_dataset):\n",
    "        data[i, :, :] = torch.tensor(np.array(d[0])[channel_index, :, :].reshape(SIDE_LENGTH, SIDE_LENGTH))\n",
    "    data = data.reshape(-1, SIDE_LENGTH*SIDE_LENGTH)\n",
    "    gc.collect()\n",
    "\n",
    "    pca = torch_pca.PCA(n_components=n_components, svd_solver='randomized')\n",
    "    pca.fit(data)\n",
    "    gc.collect()\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May take a couple of minutes, depending on parameters\n",
    "pcas = [channel_pca(channel, 100) for channel in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PCA results as a .pt file\n",
    "# torch.save({\n",
    "#     'components0': pcas[0].mean_,\n",
    "#     'explained_variance0': pcas[0].explained_variance_,\n",
    "#     'mean0': pcas[0].components_,\n",
    "#     'components1': pcas[1].mean_,\n",
    "#     'explained_variance1': pcas[1].explained_variance_,\n",
    "#     'mean1': pcas[1].components_,\n",
    "#     'components2': pcas[2].mean_,\n",
    "#     'explained_variance2': pcas[2].explained_variance_,\n",
    "#     'mean2': pcas[2].components_,\n",
    "# }, f'pcas{pcas[0].n_components_}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_img(idx: int):\n",
    "    \"\"\"Returns the given test image as a torch tensor with shape (s, s, 3).\"\"\"\n",
    "    global test_dataset\n",
    "    return torch.tensor(np.array(test_dataset[idx][0]), dtype=torch.float32).permute(1, 2, 0)\n",
    "\n",
    "def pca_project(pcas, idx: int, n=None):\n",
    "    \"\"\"Projects the given test image on n PCA components, or all available if `n` is unspecified.\"\"\"\n",
    "    global SIDE_LENGTH\n",
    "    nc = pcas[0].n_components_\n",
    "    n = nc if n is None else n\n",
    "    p = torch.cat((torch.ones(n), torch.zeros(nc-n)), dim=0)\n",
    "    sl = SIDE_LENGTH\n",
    "    img = load_test_img(idx)\n",
    "    tchs = [pca.inverse_transform(pca.transform(img[:, :, ch].reshape(1, -1)) * p).reshape(sl, sl, 1) for (ch, pca) in enumerate(pcas)]\n",
    "    return torch.cat(tchs, dim=2)\n",
    "\n",
    "def pca_multi_project(pcas, idx: int):\n",
    "    \"\"\"Projects the given test image on all PCA components.\n",
    "    Returns a (3, nc+1, s, s) tensor with the [:, 0, :, :] tensor representing channel-wise means, \n",
    "    and [:, n, :, :] are projections on the n first components (incl. means).\"\"\"\n",
    "    global SIDE_LENGTH\n",
    "    nc = pcas[0].n_components_\n",
    "    sl = SIDE_LENGTH\n",
    "    img = load_test_img(idx)\n",
    "    with torch.no_grad():\n",
    "        out = torch.zeros((3, nc+1, sl, sl))\n",
    "        for (ch, pca) in enumerate(pcas):\n",
    "            x = pca.transform(img[:, :, ch].reshape(1, -1))\n",
    "            out[ch, 1:, :, :] = torch.matmul(pca.components_.transpose(0, 1), torch.diag(x.flatten())).reshape(nc, sl, sl)\n",
    "            out[ch, 0, :, :] = pca.mean_.reshape(sl, sl)\n",
    "        out = torch.cumsum(out, dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(t):\n",
    "    return Image.fromarray(torch.clamp(255*t, 0, 255).byte().numpy())\n",
    "\n",
    "def show_test_img(idx):\n",
    "    return Image.fromarray(np.array((255*test_dataset[idx][0]).byte()).transpose((1, 2, 0)))\n",
    "\n",
    "def normalize_gray(x: torch.Tensor):\n",
    "    \"\"\"Normalizes 0 to 0.5, and scales everything evenly so that all elements are in [0, 1].\n",
    "    (Almost surely) either the smallest element will be 0 or the largest will be 1.\"\"\"\n",
    "    return 0.5 + x/(2*torch.max(torch.abs(x)))\n",
    "\n",
    "def normalize_01(x: torch.Tensor):\n",
    "    \"\"\"Normalizes x so that the smallest element is 0 and the largest is 1.\"\"\"\n",
    "    return (x-torch.min(x))/(torch.max(x)-torch.min(x))\n",
    "\n",
    "def get_component(pcas, idx):\n",
    "    global SIDE_LENGTH\n",
    "    nc = pcas[0].n_components_\n",
    "    sl = SIDE_LENGTH\n",
    "    if idx == -1:\n",
    "        return torch.cat([(pca.mean_).reshape(sl, sl, 1) for pca in pcas], dim=2)\n",
    "    p = torch.eye(nc)[idx]\n",
    "    q = torch.cat([(pca.inverse_transform(p)-pca.mean_).reshape(sl, sl, 1) for pca in pcas], dim=2)\n",
    "    # Attempt to align the components in sign.\n",
    "    for ch in [1, 2]:\n",
    "        flip = torch.sign(torch.dot(q[:, :, 0].flatten(), q[:, :, ch].flatten()))\n",
    "        assert flip != 0, f\"The {idx}th components for channel 0 and {ch} are orthogonal. This is extremely unlikely.\"\n",
    "        q[:, :, ch] *= flip\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 4\n",
    "num_cols = 4  # Adjust based on how many images you want to plot\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(8, 8))\n",
    "\n",
    "ax = axes[0,0]\n",
    "ax.imshow(show_img(get_component(pcas, -1)))\n",
    "ax.axis('off')\n",
    "ax.set_title('Âµ', fontsize=10)\n",
    "\n",
    "for i in range(num_rows * num_cols-1):\n",
    "    ax = axes[(i+1) // num_cols, (i+1) % num_cols]\n",
    "    ax.imshow(show_img(normalize_gray(get_component(pcas, i))))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'C{i+1}', fontsize=10)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 100\n",
    "num_rows = 3\n",
    "num_cols = 3  # Adjust based on how many images you want to plot\n",
    "nc = pcas[0].n_components_\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(6, 6))\n",
    "\n",
    "ax = axes[0,0]\n",
    "ax.imshow(show_test_img(idx))\n",
    "ax.axis('off')\n",
    "ax.set_title('Original', fontsize=10)\n",
    "\n",
    "for i in range(num_rows*num_cols-1):\n",
    "    n = round(np.linspace(0, nc, num_rows*num_cols-1)[i])\n",
    "    ax = axes[(i+1) // num_cols, (i+1) % num_cols]\n",
    "    ax.imshow(show_img(pca_project(pcas, idx, n=n)))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{n}C', fontsize=10)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show_img(pca_project(pcas, idx, n=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veeery slow...\n",
    "l = len(test_dataset)\n",
    "nc = pcas[0].n_components_\n",
    "\n",
    "mse = np.zeros((l, nc))\n",
    "ssim = np.zeros((l, nc))\n",
    "psnr = np.zeros((l, nc))\n",
    "\n",
    "# This may benefit from parallelization\n",
    "# For N=100 with step 0, should take just under 1hr.\n",
    "for i in tqdm(range(l)):\n",
    "    original = np.array(load_test_img(i)) # (128, 128, 3)\n",
    "    original_bc = np.broadcast_to(original[None, :, :, :], (nc, *original.shape)) # (nc, 128, 128, 3)\n",
    "    cprojected = np.array(pca_multi_project(pcas, i)).transpose((1, 2, 3, 0))[1:, :, :, :] # (nc, 128, 128, 3)\n",
    "    mse[i, :] = np.mean(np.square(cprojected - original_bc), axis=(1,2,3))\n",
    "    # ssim[i, :] = structural_similarity(original_bc, cprojected, data_range=1, channel_axis=3) # Faster when unvectorized.\n",
    "    psnr[i, :] = peak_signal_noise_ratio(original_bc, cprojected, data_range=1)\n",
    "    for n in range(nc):\n",
    "        # mse[i, n] = np.mean(np.square(projected - original))\n",
    "        ssim[i, n] = structural_similarity(original, cprojected[n, :, :, :], data_range=1, channel_axis=2) # Faster when unvectorized for some reason.\n",
    "        # psnr[i, n] = peak_signal_noise_ratio(original, cprojected[n, :, :, :], data_range=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'mse': torch.tensor(mse),\n",
    "    'ssim': torch.tensor(ssim),\n",
    "    'psnr': torch.tensor(psnr)\n",
    "}, 'pca_test_metrics.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('pca_test_metrics.pt', weights_only=True)\n",
    "mse = np.array(data['mse'])\n",
    "ssim = np.array(data['ssim'])\n",
    "psnr = np.array(data['psnr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X axis is number of components.\n",
    "plt.plot(np.mean(mse, axis=0))\n",
    "plt.xlabel(\"Component count\")\n",
    "plt.ylabel(\"Pixel MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(psnr, axis=0))\n",
    "plt.xlabel(\"Component count\")\n",
    "plt.ylabel(\"PSNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(ssim, axis=0))\n",
    "plt.xlabel(\"Component count\")\n",
    "plt.ylabel(\"SSIM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
